# Chat IA Local (Ollama)

AplicaciÃ³n web y de escritorio para chatear con modelos de IA locales usando Ollama. FÃ¡cil de usar, multiplataforma y con interfaz moderna.

---

## ğŸš€ CaracterÃ­sticas

- Interfaz moderna, responsive y modo oscuro
- ConexiÃ³n directa a Ollama (local)
- Selector de modelo y URL de API
- Historial y exportaciÃ³n de chat
- Atajos de teclado
- Soporte para Markdown
- App web y escritorio (Electron)

---

## ğŸ“‹ Requisitos

- [Ollama](https://ollama.ai/) instalado y ejecutÃ¡ndose
- Al menos un modelo descargado (ej: `llama3:8b`)
- Node.js 18+ y npm
- (Para escritorio) Windows, Linux o Mac

---

## ğŸ“ Estructura del Proyecto

```
ia/
â”œâ”€â”€ package.json           # ConfiguraciÃ³n principal (npm, scripts, Electron)
â”œâ”€â”€ .gitignore             # ExclusiÃ³n de archivos
â”œâ”€â”€ public/                # App web (HTML, CSS, JS, assets, package.json)
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ styles.css
â”‚   â”œâ”€â”€ script.js
â”‚   â”œâ”€â”€ assets/
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ electron/              # CÃ³digo principal de Electron
â”‚   â”œâ”€â”€ main.js
â”‚   â””â”€â”€ preload.js
â”œâ”€â”€ tools/                 # Scripts y utilidades
â”‚   â”œâ”€â”€ build-win.js
â”‚   â”œâ”€â”€ package-win.js
â”‚   â”œâ”€â”€ proxy.py
â”‚   â””â”€â”€ bfg-1.15.0.jar
â”œâ”€â”€ docs/                  # DocumentaciÃ³n
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ DESKTOP_APP.md
â”‚   â””â”€â”€ BUILD_INSTRUCTIONS.md
â””â”€â”€ dist/                  # Builds generados
```

---

## ğŸ› ï¸ InstalaciÃ³n y Primer Uso

### 1. Clona el repositorio y entra al directorio

```bash
# Windows, Linux o Mac
 git clone https://github.com/tu-usuario/chat-ia-local.git
 cd chat-ia-local
```

### 2. Instala dependencias

```bash
npm install
```

### 3. Descarga y ejecuta Ollama

```bash
# Instala Ollama (ver https://ollama.ai/download)
# Descarga un modelo
ollama pull llama3:8b
# Inicia el servidor
ollama serve
```

---

## ğŸš¦ Modo Web (servidor local)

```bash
npm start
```

- Abre tu navegador en: [http://localhost:8000](http://localhost:8000)
- Si el puerto 8000 estÃ¡ ocupado, revisa la consola para el puerto alternativo.

---

## ğŸ–¥ï¸ Modo Escritorio (Electron)

```bash
npm run electron
```

- Se abrirÃ¡ la app de escritorio.
- Si tienes problemas, asegÃºrate de que Ollama estÃ© corriendo y el modelo descargado.

---

## âš™ï¸ ConfiguraciÃ³n

- Haz clic en el engranaje (âš™ï¸) para abrir el modal de configuraciÃ³n.
- Cambia la URL del API (por defecto: `http://localhost:11434`)
- Selecciona el modelo de IA disponible (ej: `llama3:8b`)

### Agregar mÃ¡s modelos

1. Descarga el modelo:
   ```bash
   ollama pull nombre-del-modelo
   ```
2. Agrega la opciÃ³n en el selector de modelo en `public/index.html`.

---

## âŒ¨ï¸ Atajos de Teclado

- **Enter**: Enviar mensaje
- **Shift + Enter**: Nueva lÃ­nea
- **Ctrl/Cmd + L**: Limpiar chat
- **Ctrl/Cmd + E**: Exportar conversaciÃ³n

---

## ğŸ†˜ SoluciÃ³n de Problemas

### Ollama no responde

- Verifica que Ollama estÃ© ejecutÃ¡ndose: `ollama serve`
- Verifica que el modelo estÃ© descargado: `ollama list`
- Prueba la API: `curl http://localhost:11434/api/tags`

### Error CORS en modo web

- Usa `npm start` o un servidor local (no abras el HTML directamente)
- Alternativamente, ejecuta el proxy: `python tools/proxy.py` y usa la URL `http://localhost:8080` en la configuraciÃ³n

### Error al iniciar Electron

- AsegÃºrate de tener Node.js y npm instalados
- Ejecuta desde la raÃ­z del proyecto: `npm run electron`
- Si ves "Cannot find Electron app", revisa que el script apunte a `electron/main.js`

---

## ğŸ¤ Contribuir

Â¡Las contribuciones son bienvenidas! Puedes:

- Reportar bugs
- Sugerir mejoras
- Mejorar la documentaciÃ³n
- Agregar soporte para mÃ¡s modelos

---

## ğŸ“„ Licencia

MIT

---

## ğŸ™ Agradecimientos

- [Ollama](https://ollama.ai/)
- Comunidad open source
