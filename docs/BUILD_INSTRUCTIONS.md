# ğŸ–¥ï¸ Instrucciones de ConstrucciÃ³n - Windows

## âœ… Â¡AplicaciÃ³n Construida Exitosamente!

Tu aplicaciÃ³n de escritorio para Windows ha sido construida y estÃ¡ lista para usar.

---

## ğŸ“ Archivos Generados

### AplicaciÃ³n Ejecutable:

- **UbicaciÃ³n**: `tools/dist/win-unpacked/`
- **Archivo principal**: `Chat IA Local.exe`
- **Script de ejecuciÃ³n**: `run.bat`

### Paquete Distribuible:

- **Archivo ZIP**: `tools/dist/Chat-IA-Local-Windows.zip`
- **Contenido**: AplicaciÃ³n completa lista para usar

---

## ğŸš€ CÃ³mo Usar la AplicaciÃ³n

### OpciÃ³n 1: Ejecutar desde el directorio

```bash
cd tools/dist/win-unpacked
run.bat
```

### OpciÃ³n 2: Ejecutar directamente

```bash
cd tools/dist/win-unpacked
node_modules\.bin\electron .
```

### OpciÃ³n 3: Doble clic

- Navega a `tools/dist/win-unpacked/`
- Haz doble clic en `Chat IA Local.exe`

---

## ğŸ“¦ DistribuciÃ³n

### Para compartir la aplicaciÃ³n:

1. **Archivo ZIP**: `tools/dist/Chat-IA-Local-Windows.zip`
2. **Extraer** en cualquier carpeta
3. **Ejecutar** `run.bat` o `Chat IA Local.exe`

### Requisitos para el usuario final:

- **Ollama** debe estar instalado y ejecutÃ¡ndose
- **Modelo de IA** debe estar descargado

---

## ğŸ› ï¸ Scripts Disponibles

### Construir aplicaciÃ³n:

```bash
npm run build-win-simple
```

### Crear paquete ZIP:

```bash
npm run package-win
```

### Construir y empaquetar todo:

```bash
npm run build-win-simple && npm run package-win
```

---

## ğŸ† CaracterÃ­sticas de la AplicaciÃ³n

- Interfaz oscura y moderna
- ConexiÃ³n directa a Ollama (sin CORS)
- MÃºltiples modelos
- Markdown en respuestas
- ConfiguraciÃ³n persistente
- ExportaciÃ³n de conversaciones
- MenÃº nativo

---

## ğŸ†˜ SoluciÃ³n de Problemas

### La aplicaciÃ³n no se ejecuta:

1. Verifica que tengas permisos de administrador
2. Ejecuta `run.bat` desde la lÃ­nea de comandos
3. Verifica que no haya antivirus bloqueando

### No se conecta a Ollama:

1. AsegÃºrate de que Ollama estÃ© ejecutÃ¡ndose: `ollama serve`
2. Verifica que tengas un modelo: `ollama list`
3. Descarga un modelo: `ollama pull llama3:8b`

### Error de dependencias:

1. Ejecuta: `npm install --production` en el directorio de la aplicaciÃ³n
2. Verifica que Node.js estÃ© instalado

---

## ğŸ“‹ Checklist de DistribuciÃ³n

- [x] AplicaciÃ³n construida
- [x] Archivo ZIP creado
- [x] Scripts de ejecuciÃ³n incluidos
- [x] DocumentaciÃ³n incluida
- [x] Dependencias incluidas
- [x] Iconos incluidos

---

## ğŸ‰ Â¡Listo para Distribuir!

Tu aplicaciÃ³n estÃ¡ completamente lista para ser compartida. Los usuarios solo necesitan:

1. **Descargar** el archivo ZIP
2. **Extraer** en cualquier carpeta
3. **Ejecutar** la aplicaciÃ³n
4. **Configurar** Ollama si es necesario

Â¡Disfruta de tu app de escritorio para chatear con IA local! ğŸ¤–âœ¨
